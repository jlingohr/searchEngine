Search Engine
-----------

The search engine is composed of 3 modules, the crawler, the indexer, and the query engine. The search engine works as follows: (1) crawler initializes a seed URL to begin crawling, extracting HTML pages and saving those pages to file, along with the URL crawled and a unique document ID; (2) Index reads HTML files saved by the crawler and parses each word and saving the unique document ID in which the word is found along with the word frequency in an inverted index. Once all HTML files are parsed and loaded into the index, the indexer saves each entry to file in the form ((word, total_docs) : (doc_ID, count)); (3) Query engine loads saved data from the indexer into an inverted index, parses a user query, ranks matching URLS by frequency, and prints result to the user.

./crawler: Contains source code for the crawler as well as the directory the crawler saves HTML files
./indexer: Contains source code the the indexer as well as the directory the indexer saves parsed HTML files
./query: Contains source code for the query engine
./tests: Contains unit tests for List and Hashtable library created for the search engine
./util: Contains source code for List and Hashtable, as well as any helper functions


Notes: Program has been compiled on OS X



__________
TODO 

  Program:
  - System testing
  - complete unit testing
  - Fix all memory leaks 

  Crawler:
  - Stop safely for problems
  - Check if a file already exists and dont append to if it already exists
  - Valgrind errors gone, but some memory leaks remain; have to check free conditions in crawPage and freeWebPage,    list_dequeue

  Indexer:
   - Fix any memory leaks 
   - Seperate modules/Libraries

  Query:
  - Test that intersect works 
  - Start testing on multuple pages
  - memory leaks and dangling pointers
  - Add kill signal
  - Error for only AND or OR query
  - Error printing repeated results